# -*- coding: utf-8 -*-
"""
Web Content Extractor Pro - ä¸“ä¸šç½‘é¡µå†…å®¹æå–å·¥å…·
åŸºäºPyQt5å’ŒBeautifulSoupå¼€å‘ï¼Œæ”¯æŒå¤šå¹³å°å†…å®¹æå–ã€å¤šæ ¼å¼è¾“å‡ºã€æ•°å­¦å…¬å¼å¤„ç†
Version: 7.0
githubç½‘å€ï¼š https://github.com/lyp0746
QQé‚®ç®±ï¼š1610369302@qq.com
ä½œè€…ï¼šLYP

åŠŸèƒ½ç‰¹æ€§:
- æ”¯æŒå¹³å°: èœé¸Ÿæ•™ç¨‹ã€CSDNåšå®¢/ä¸“æ ã€çŸ¥ä¹ä¸“æ ã€ç®€ä¹¦
- è¾“å‡ºæ ¼å¼: Markdownã€HTMLã€PDF (ä¸“ä¸šä¹¦ç±é£æ ¼)
- æ•°å­¦å…¬å¼: å®Œæ•´LaTeX/MathJax 3.0æ”¯æŒ
- CSDNå¢å¼º: æ·±åº¦å†…å®¹æå–å’Œæ¸…ç†
- GUIä¼˜åŒ–: å¤§å­—ä½“ã€æ˜“æ“ä½œã€ä¸“ä¸šå¤–è§‚
============================================
"""
import sys
import os
import re
from pathlib import Path
from typing import List, Tuple
from urllib.parse import urljoin, urlparse
import time
from datetime import datetime

import requests
from bs4 import BeautifulSoup
from PyQt5.QtWidgets import *
from PyQt5.QtCore import QThread, pyqtSignal, Qt, QSettings
from PyQt5.QtGui import QFont, QTextCursor

# PDFç”Ÿæˆ - WeasyPrint 59.0+
try:
    from weasyprint import HTML, CSS
    from weasyprint.text.fonts import FontConfiguration
    WEASY_AVAILABLE = True
except ImportError:
    WEASY_AVAILABLE = False


# ======================== æ•°æ®ç»“æ„ ========================
class Article:
    """æ–‡ç« æ•°æ®ç»“æ„"""
    def __init__(self, title: str, url: str, level: int = 1):
        self.title = title
        self.url = url
        self.level = level
        self.content = ""
        self.html_content = ""
        self.author = ""
        self.date = ""
        self.category = ""


# ======================== çˆ¬è™«åŸºç±» ========================
class BaseCrawler:
    """çˆ¬è™«åŸºç±» - æä¾›é€šç”¨åŠŸèƒ½"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        }
        self.session = requests.Session()
        self.img_cache = {}
        
    def download_image(self, url: str, img_dir: str, referer: str = None) -> str:
        """ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°"""
        try:
            if url in self.img_cache:
                return self.img_cache[url]
            
            headers = self.headers.copy()
            if referer:
                headers['Referer'] = referer
            
            response = self.session.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                # è·å–æ‰©å±•å
                content_type = response.headers.get('content-type', '')
                ext_map = {
                    'image/png': '.png',
                    'image/jpeg': '.jpg',
                    'image/jpg': '.jpg',
                    'image/gif': '.gif',
                    'image/webp': '.webp',
                    'image/svg+xml': '.svg'
                }
                ext = '.png'
                for mime, extension in ext_map.items():
                    if mime in content_type:
                        ext = extension
                        break
                
                img_name = f"img_{abs(hash(url))}{ext}"
                img_path = os.path.join(img_dir, img_name)
                
                with open(img_path, 'wb') as f:
                    f.write(response.content)
                
                result = f"images/{img_name}"
                self.img_cache[url] = result
                return result
                
        except Exception as e:
            print(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {url}, {e}")
        
        return url
    
    def clean_html(self, soup):
        """æ¸…ç†HTML - ç§»é™¤æ— å…³å…ƒç´ """
        # ç§»é™¤è„šæœ¬å’Œæ ·å¼
        for tag in soup.find_all(['script', 'style', 'iframe', 'noscript']):
            tag.decompose()
        
        # ç§»é™¤å¹¿å‘Šå…ƒç´ 
        ad_patterns = [
            'ad', 'advertisement', 'adsbygoogle', 'sponsor', 
            'promo', 'banner', 'popup', 'modal'
        ]
        for pattern in ad_patterns:
            for tag in soup.find_all(class_=re.compile(pattern, re.I)):
                tag.decompose()
        
        return soup
    
    def process_math_formulas(self, content):
        """
        å¢å¼ºæ•°å­¦å…¬å¼å¤„ç†
        æ”¯æŒæ ¼å¼:
        - LaTeXè¡Œå†…: \( ... \) æˆ– $ ... $
        - LaTeXå—çº§: \[ ... \] æˆ– $$ ... $$
        - MathJax scriptæ ‡ç­¾
        """
        content_str = str(content)
        
        # LaTeXè¡Œå†…å…¬å¼: \( ... \)
        content_str = re.sub(
            r'\\\\?\((.*?)\\\\?\)', 
            r'<span class="math-inline">$\1$</span>', 
            content_str
        )
        
        # LaTeXå—çº§å…¬å¼: \[ ... \]
        content_str = re.sub(
            r'\\\\?\[(.*?)\\\\?\]', 
            r'<div class="math-display">$$\1$$</div>', 
            content_str, 
            flags=re.DOTALL
        )
        
        # å¤„ç†MathJax scriptæ ‡ç­¾
        soup = BeautifulSoup(content_str, 'html.parser')
        
        # è¡Œå†…å…¬å¼
        for script in soup.find_all('script', type='math/tex'):
            formula = script.string
            if formula:
                span = soup.new_tag('span', attrs={'class': 'math-inline'})
                span.string = f'${formula}$'
                script.replace_with(span)
        
        # å—çº§å…¬å¼
        for script in soup.find_all('script', type='math/tex; mode=display'):
            formula = script.string
            if formula:
                div = soup.new_tag('div', attrs={'class': 'math-display'})
                div.string = f'$${formula}$$'
                script.replace_with(div)
        
        # å¤„ç†CSDNçš„å…¬å¼æ ‡è®°
        for span in soup.find_all('span', class_=re.compile('katex|mathjax')):
            formula_text = span.get_text()
            if formula_text:
                new_span = soup.new_tag('span', attrs={'class': 'math-inline'})
                new_span.string = f'${formula_text}$'
                span.replace_with(new_span)
        
        return soup


# ======================== èœé¸Ÿæ•™ç¨‹çˆ¬è™« ========================
class RunoobCrawler(BaseCrawler):
    """èœé¸Ÿæ•™ç¨‹çˆ¬è™«"""
    
    def extract_tutorial_info(self, url: str) -> Tuple[str, List[Article]]:
        response = self.session.get(url, headers=self.headers, timeout=15)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # æå–æ ‡é¢˜
        title_tag = soup.find('h1') or soup.find('title')
        title = title_tag.get_text().strip() if title_tag else "æœªçŸ¥æ•™ç¨‹"
        title = re.sub(r'\s*[-|]?\s*èœé¸Ÿæ•™ç¨‹.*', '', title)
        
        # æå–ç« èŠ‚
        articles = []
        sidebar = soup.find('div', {'id': 'leftcolumn'})
        
        if sidebar:
            links = sidebar.find_all('a')
            for link in links:
                href = link.get('href')
                if href and not href.startswith('#') and not href.startswith('javascript'):
                    full_url = urljoin(url, href)
                    link_title = link.get_text().strip()
                    if link_title and len(link_title) > 1:
                        articles.append(Article(link_title, full_url))
        
        # å»é‡
        seen = set()
        unique = []
        for art in articles:
            if art.url not in seen:
                seen.add(art.url)
                unique.append(art)
        
        return title, unique
    
    def extract_article_content(self, article: Article, download_images: bool, img_dir: str):
        try:
            response = self.session.get(article.url, headers=self.headers, timeout=15)
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'html.parser')
            
            content = soup.find('div', {'id': 'content'}) or soup.find('article') or soup.find('div', class_='article-intro')
            
            if not content:
                article.content = "_å†…å®¹è·å–å¤±è´¥_"
                article.html_content = "<p><em>å†…å®¹è·å–å¤±è´¥</em></p>"
                return
            
            content = self.clean_html(content)
            content = self.process_math_formulas(content)
            
            # å¤„ç†å›¾ç‰‡
            if download_images:
                for img in content.find_all('img'):
                    src = img.get('src') or img.get('data-src')
                    if src:
                        img_url = urljoin(article.url, src)
                        local_path = self.download_image(img_url, img_dir)
                        img['src'] = local_path
                        if not img.get('alt'):
                            img['alt'] = 'image'
            
            # å¤„ç†ä»£ç å—
            for pre in content.find_all('pre'):
                pre['class'] = 'code-block'
            
            article.html_content = str(content)
            article.content = self.html_to_markdown(content)
            
        except Exception as e:
            article.content = f"_æå–å¤±è´¥: {str(e)}_"
            article.html_content = f"<p><em>æå–å¤±è´¥: {str(e)}</em></p>"
    
    def html_to_markdown(self, content) -> str:
        lines = []
        for element in content.find_all(['h1', 'h2', 'h3', 'h4', 'p', 'pre', 'ul', 'ol', 'blockquote']):
            tag = element.name
            text = element.get_text().strip()
            
            if tag == 'h1' and text:
                lines.append(f"\n# {text}\n")
            elif tag == 'h2' and text:
                lines.append(f"\n## {text}\n")
            elif tag == 'h3' and text:
                lines.append(f"\n### {text}\n")
            elif tag == 'h4' and text:
                lines.append(f"\n#### {text}\n")
            elif tag == 'p' and text:
                lines.append(f"\n{text}\n")
            elif tag == 'pre':
                lines.append(f"\n```\n{element.get_text()}\n```\n")
            elif tag == 'blockquote' and text:
                lines.append(f"\n> {text}\n")
        
        return ''.join(lines)


# ======================== CSDNçˆ¬è™« - å¢å¼ºç‰ˆ ========================
class CSDNCrawler(BaseCrawler):
    """CSDNåšå®¢çˆ¬è™« - å¢å¼ºå†…å®¹æå–"""
    
    def __init__(self):
        super().__init__()
        self.headers.update({
            'Referer': 'https://blog.csdn.net/',
            'Cookie': 'uuid_tt_dd=10_12345678-1234567890123-0123456789012-0123456789012'
        })
    
    def extract_column_articles(self, url: str) -> List[Article]:
        """æå–ä¸“æ æ–‡ç« åˆ—è¡¨"""
        articles = []
        
        try:
            response = self.session.get(url, headers=self.headers, timeout=15)
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # å¤šç§æ–¹å¼æŸ¥æ‰¾æ–‡ç« åˆ—è¡¨
            selectors = [
                ('div', {'class': 'column_article_list'}),
                ('div', {'class': re.compile('article.*item')}),
                ('div', {'class': re.compile('blog.*item')}),
                ('article', {}),
            ]
            
            article_items = []
            for tag, attrs in selectors:
                items = soup.find_all(tag, attrs)
                if items:
                    article_items.extend(items)
                    break
            
            # æå–æ–‡ç« é“¾æ¥
            for item in article_items:
                link = item.find('a', href=re.compile('/article/details/'))
                if link:
                    title = link.get_text().strip()
                    href = link.get('href')
                    if not href.startswith('http'):
                        href = urljoin('https://blog.csdn.net', href)
                    articles.append(Article(title, href))
            
            # å¦‚æœä¸Šè¿°æ–¹æ³•éƒ½å¤±è´¥ï¼Œç›´æ¥æŸ¥æ‰¾æ‰€æœ‰æ–‡ç« é“¾æ¥
            if not articles:
                links = soup.find_all('a', href=re.compile('/article/details/'))
                for link in links:
                    title = link.get_text().strip()
                    if title and len(title) > 5:
                        href = link.get('href')
                        if not href.startswith('http'):
                            href = urljoin('https://blog.csdn.net', href)
                        articles.append(Article(title, href))
            
        except Exception as e:
            print(f"æå–ä¸“æ æ–‡ç« å¤±è´¥: {e}")
        
        # å»é‡
        seen = set()
        unique = []
        for art in articles:
            if art.url not in seen and '/article/details/' in art.url:
                seen.add(art.url)
                unique.append(art)
        
        return unique
    
    def extract_article_info(self, article: Article):
        """æå–æ–‡ç« å…ƒä¿¡æ¯"""
        try:
            response = self.session.get(article.url, headers=self.headers, timeout=15)
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æå–æ ‡é¢˜
            if not article.title or article.title == "æœªå‘½å":
                title_selectors = [
                    ('h1', {'class': 'title-article'}),
                    ('h1', {'id': 'articleContentId'}),
                    ('h1', {}),
                ]
                for tag, attrs in title_selectors:
                    title_tag = soup.find(tag, attrs)
                    if title_tag:
                        article.title = title_tag.get_text().strip()
                        break
            
            # æå–ä½œè€…
            author_selectors = [
                ('a', {'class': 'follow-nickName'}),
                ('a', {'class': re.compile('user.*name')}),
                ('div', {'class': 'user-info'}),
            ]
            for tag, attrs in author_selectors:
                author_tag = soup.find(tag, attrs)
                if author_tag:
                    article.author = author_tag.get_text().strip()
                    break
            
            # æå–æ—¥æœŸ
            date_selectors = [
                ('span', {'class': 'time'}),
                ('span', {'class': re.compile('date|time')}),
            ]
            for tag, attrs in date_selectors:
                date_tag = soup.find(tag, attrs)
                if date_tag:
                    article.date = date_tag.get_text().strip()
                    break
            
            # æå–åˆ†ç±»
            category_tag = soup.find('a', {'class': 'tag-link'})
            if category_tag:
                article.category = category_tag.get_text().strip()
            
        except Exception as e:
            print(f"æå–æ–‡ç« ä¿¡æ¯å¤±è´¥: {e}")
    
    def extract_article_content(self, article: Article, download_images: bool, img_dir: str):
        """å¢å¼ºçš„å†…å®¹æå–"""
        try:
            self.extract_article_info(article)
            
            response = self.session.get(article.url, headers=self.headers, timeout=15)
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # å¤šç§æ–¹å¼æŸ¥æ‰¾å†…å®¹åŒºåŸŸ
            content_selectors = [
                ('div', {'id': 'content_views'}),
                ('div', {'class': 'article_content'}),
                ('div', {'class': re.compile('article.*content')}),
                ('article', {}),
            ]
            
            content = None
            for tag, attrs in content_selectors:
                content = soup.find(tag, attrs)
                if content:
                    break
            
            if not content:
                article.content = "_å†…å®¹è·å–å¤±è´¥_"
                article.html_content = "<p><em>å†…å®¹è·å–å¤±è´¥</em></p>"
                return
            
            # æ¸…ç†HTML
            content = self.clean_html(content)
            
            # ç§»é™¤CSDNç‰¹æœ‰çš„å¹²æ‰°å…ƒç´ 
            csdn_noise_patterns = [
                'hljs-button', 'csdn-tracking', 'hide-article',
                'blog-content-box', 'recommend-box', 'comment-box',
                'tool-box', 'more-toolbox', 'opt-box'
            ]
            for pattern in csdn_noise_patterns:
                for tag in content.find_all(class_=re.compile(pattern, re.I)):
                    tag.decompose()
            
            # ç§»é™¤"å·²æ”¶å½•"ç­‰æç¤º
            for tag in content.find_all(text=re.compile('å·²æ”¶å½•|ç‰ˆæƒå£°æ˜|Â©ï¸|æŸ¥çœ‹åŸæ–‡')):
                parent = tag.parent
                if parent:
                    parent.decompose()
            
            # å¤„ç†å›¾ç‰‡ - CSDNéœ€è¦ç‰¹æ®Šå¤„ç†
            if download_images:
                for img in content.find_all('img'):
                    # CSDNå›¾ç‰‡å¯èƒ½åœ¨å¤šä¸ªå±æ€§ä¸­
                    src = img.get('src') or img.get('data-src') or img.get('data-original-src')
                    if src:
                        img_url = urljoin(article.url, src)
                        local_path = self.download_image(img_url, img_dir, article.url)
                        img['src'] = local_path
                        if not img.get('alt'):
                            img['alt'] = 'image'
            
            # å¤„ç†æ•°å­¦å…¬å¼ - å¢å¼ºæ”¯æŒ
            content = self.process_math_formulas(content)
            
            # å¤„ç†ä»£ç å—
            for pre in content.find_all('pre'):
                # ä¿ç•™ä»£ç å—çš„è¯­è¨€æ ‡è¯†
                code_tag = pre.find('code')
                if code_tag:
                    lang = code_tag.get('class', [''])[0]
                    if lang.startswith('language-'):
                        lang = lang.replace('language-', '')
                        pre['data-lang'] = lang
                pre['class'] = 'code-block'
            
            article.html_content = str(content)
            article.content = self.html_to_markdown(content)
            
        except Exception as e:
            article.content = f"_æå–å¤±è´¥: {str(e)}_"
            article.html_content = f"<p><em>æå–å¤±è´¥: {str(e)}</em></p>"
    
    def html_to_markdown(self, content) -> str:
        lines = []
        for element in content.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'pre', 'blockquote']):
            tag = element.name
            text = element.get_text().strip()
            
            if tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6'] and text:
                level = int(tag[1])
                lines.append(f"\n{'#' * level} {text}\n")
            elif tag == 'p' and text:
                lines.append(f"\n{text}\n")
            elif tag == 'pre':
                # å°è¯•è·å–è¯­è¨€æ ‡è¯†
                lang = element.get('data-lang', '')
                lines.append(f"\n```{lang}\n{element.get_text()}\n```\n")
            elif tag == 'blockquote' and text:
                lines.append(f"\n> {text}\n")
        
        return ''.join(lines)


# ======================== çŸ¥ä¹çˆ¬è™« ========================
class ZhihuCrawler(BaseCrawler):
    """çŸ¥ä¹ä¸“æ çˆ¬è™«"""
    
    def __init__(self):
        super().__init__()
        self.headers.update({
            'Referer': 'https://www.zhihu.com/',
        })
    
    def extract_article_content(self, article: Article, download_images: bool, img_dir: str):
        try:
            response = self.session.get(article.url, headers=self.headers, timeout=15)
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æå–æ ‡é¢˜
            if not article.title or article.title == "æœªå‘½å":
                title_tag = soup.find('h1', class_='Post-Title') or soup.find('h1')
                article.title = title_tag.get_text().strip() if title_tag else "æœªçŸ¥æ–‡ç« "
            
            # æå–ä½œè€…
            author_tag = soup.find('meta', attrs={'name': 'author'})
            article.author = author_tag.get('content') if author_tag else "æœªçŸ¥ä½œè€…"
            
            # æå–å†…å®¹
            content = soup.find('div', class_='Post-RichText') or soup.find('div', class_='RichText')
            
            if not content:
                article.content = "_å†…å®¹è·å–å¤±è´¥_"
                article.html_content = "<p><em>å†…å®¹è·å–å¤±è´¥</em></p>"
                return
            
            content = self.clean_html(content)
            content = self.process_math_formulas(content)
            
            # å¤„ç†å›¾ç‰‡
            if download_images:
                for img in content.find_all('img'):
                    src = img.get('src') or img.get('data-original') or img.get('data-actualsrc')
                    if src:
                        img_url = urljoin(article.url, src)
                        local_path = self.download_image(img_url, img_dir, article.url)
                        img['src'] = local_path
            
            article.html_content = str(content)
            article.content = self.html_to_markdown(content)
            
        except Exception as e:
            article.content = f"_æå–å¤±è´¥: {str(e)}_"
            article.html_content = f"<p><em>æå–å¤±è´¥: {str(e)}</em></p>"
    
    def html_to_markdown(self, content) -> str:
        lines = []
        for element in content.find_all(['h1', 'h2', 'h3', 'h4', 'p', 'pre', 'blockquote']):
            tag = element.name
            text = element.get_text().strip()
            
            if tag in ['h1', 'h2', 'h3', 'h4'] and text:
                level = int(tag[1])
                lines.append(f"\n{'#' * level} {text}\n")
            elif tag == 'p' and text:
                lines.append(f"\n{text}\n")
            elif tag == 'pre':
                lines.append(f"\n```\n{element.get_text()}\n```\n")
            elif tag == 'blockquote' and text:
                lines.append(f"\n> {text}\n")
        
        return ''.join(lines)


# ======================== ç®€ä¹¦çˆ¬è™« ========================
class JianshuCrawler(BaseCrawler):
    """ç®€ä¹¦çˆ¬è™«"""
    
    def __init__(self):
        super().__init__()
        self.headers.update({
            'Referer': 'https://www.jianshu.com/',
        })
    
    def extract_article_content(self, article: Article, download_images: bool, img_dir: str):
        try:
            response = self.session.get(article.url, headers=self.headers, timeout=15)
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æå–æ ‡é¢˜
            if not article.title or article.title == "æœªå‘½å":
                title_tag = soup.find('h1', class_='title') or soup.find('h1')
                article.title = title_tag.get_text().strip() if title_tag else "æœªçŸ¥æ–‡ç« "
            
            # æå–ä½œè€…
            author_tag = soup.find('a', class_='author')
            article.author = author_tag.get_text().strip() if author_tag else "æœªçŸ¥ä½œè€…"
            
            # æå–å†…å®¹
            content = soup.find('article') or soup.find('div', class_='show-content')
            
            if not content:
                article.content = "_å†…å®¹è·å–å¤±è´¥_"
                article.html_content = "<p><em>å†…å®¹è·å–å¤±è´¥</em></p>"
                return
            
            content = self.clean_html(content)
            content = self.process_math_formulas(content)
            
            # å¤„ç†å›¾ç‰‡
            if download_images:
                for img in content.find_all('img'):
                    src = img.get('src') or img.get('data-original-src')
                    if src:
                        img_url = urljoin(article.url, src)
                        local_path = self.download_image(img_url, img_dir, article.url)
                        img['src'] = local_path
            
            article.html_content = str(content)
            article.content = self.html_to_markdown(content)
            
        except Exception as e:
            article.content = f"_æå–å¤±è´¥: {str(e)}_"
            article.html_content = f"<p><em>æå–å¤±è´¥: {str(e)}</em></p>"
    
    def html_to_markdown(self, content) -> str:
        lines = []
        for element in content.find_all(['h1', 'h2', 'h3', 'h4', 'p', 'pre', 'blockquote']):
            tag = element.name
            text = element.get_text().strip()
            
            if tag in ['h1', 'h2', 'h3', 'h4'] and text:
                level = int(tag[1])
                lines.append(f"\n{'#' * level} {text}\n")
            elif tag == 'p' and text:
                lines.append(f"\n{text}\n")
            elif tag == 'pre':
                lines.append(f"\n```\n{element.get_text()}\n```\n")
            elif tag == 'blockquote' and text:
                lines.append(f"\n> {text}\n")
        
        return ''.join(lines)


# ======================== çˆ¬è™«çº¿ç¨‹ ========================
class CrawlerThread(QThread):
    """çˆ¬è™«çº¿ç¨‹ - å¢å¼ºç‰ˆ"""
    progress_signal = pyqtSignal(str)
    finished_signal = pyqtSignal(bool, str)
    
    def __init__(self):
        super().__init__()
        self.url = ""
        self.platform = "runoob"
        self.output_dir = "./output"
        self.output_formats = ['markdown', 'html', 'pdf']
        self.download_images = True
        self.aggregate_mode = True  # True=åˆå¹¶æˆä¸€ä¸ªæ–‡ä»¶ï¼ŒFalse=æ¯ç¯‡ç‹¬ç«‹æ–‡ä»¶
        self.is_running = True
        
    def run(self):
        try:
            Path(self.output_dir).mkdir(parents=True, exist_ok=True)
            img_dir = os.path.join(self.output_dir, 'images')
            Path(img_dir).mkdir(parents=True, exist_ok=True)
            
            if self.platform == 'runoob':
                self.crawl_runoob()
            elif self.platform == 'csdn':
                self.crawl_csdn()
            elif self.platform == 'zhihu':
                self.crawl_zhihu()
            elif self.platform == 'jianshu':
                self.crawl_jianshu()
            
            self.finished_signal.emit(True, f"âœ… å®Œæˆ!\nä¿å­˜ä½ç½®: {os.path.abspath(self.output_dir)}")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            self.finished_signal.emit(False, f"âŒ é”™è¯¯: {str(e)}\n\n{error_detail}")
    
    def stop(self):
        self.is_running = False
    
    def crawl_runoob(self):
        self.progress_signal.emit("ğŸ“– æ­£åœ¨åˆ†æèœé¸Ÿæ•™ç¨‹...")
        
        crawler = RunoobCrawler()
        title, articles = crawler.extract_tutorial_info(self.url)
        
        if not articles:
            raise Exception("æœªæ‰¾åˆ°ä»»ä½•ç« èŠ‚")
        
        self.progress_signal.emit(f"ğŸ“š æ•™ç¨‹: {title}")
        self.progress_signal.emit(f"ğŸ“‘ å…± {len(articles)} ä¸ªç« èŠ‚")
        
        img_dir = os.path.join(self.output_dir, 'images')
        
        for idx, article in enumerate(articles, 1):
            if not self.is_running:
                return
            
            self.progress_signal.emit(f"ğŸ“„ [{idx}/{len(articles)}] {article.title}")
            crawler.extract_article_content(article, self.download_images, img_dir)
            time.sleep(0.5)
        
        # æ ¹æ®æ¨¡å¼ç”Ÿæˆæ–‡ä»¶
        if self.aggregate_mode:
            self.generate_files(title, articles, "èœé¸Ÿæ•™ç¨‹")
        else:
            self.generate_separate_files(articles, "èœé¸Ÿæ•™ç¨‹")
    
    def crawl_csdn(self):
        self.progress_signal.emit("ğŸ“– æ­£åœ¨åˆ†æCSDN...")
        
        crawler = CSDNCrawler()
        
        if '/category_' in self.url or '/column/' in self.url:
            self.progress_signal.emit("ğŸ“š æ£€æµ‹åˆ°ä¸“æ ï¼Œæ­£åœ¨æå–æ–‡ç« åˆ—è¡¨...")
            articles = crawler.extract_column_articles(self.url)
            
            if not articles:
                raise Exception("æœªæ‰¾åˆ°ä»»ä½•æ–‡ç« ")
            
            self.progress_signal.emit(f"ğŸ“‘ å…± {len(articles)} ç¯‡æ–‡ç« ")
            
            img_dir = os.path.join(self.output_dir, 'images')
            
            for idx, article in enumerate(articles, 1):
                if not self.is_running:
                    return
                
                self.progress_signal.emit(f"ğŸ“„ [{idx}/{len(articles)}] {article.title}")
                crawler.extract_article_content(article, self.download_images, img_dir)
                time.sleep(1)
            
            title = articles[0].author + "çš„CSDNä¸“æ " if articles else "CSDNä¸“æ "
            
            if self.aggregate_mode:
                self.generate_files(title, articles, articles[0].author if articles else "æœªçŸ¥ä½œè€…")
            else:
                self.generate_separate_files(articles, articles[0].author if articles else "æœªçŸ¥ä½œè€…")
            
        else:
            article = Article("æœªå‘½å", self.url)
            
            img_dir = os.path.join(self.output_dir, 'images')
            self.progress_signal.emit("ğŸ“„ æ­£åœ¨æå–æ–‡ç« å†…å®¹...")
            crawler.extract_article_content(article, self.download_images, img_dir)
            
            self.generate_files(article.title, [article], article.author)
    
    def crawl_zhihu(self):
        """çˆ¬å–çŸ¥ä¹ä¸“æ """
        self.progress_signal.emit("ğŸ“– æ­£åœ¨åˆ†æçŸ¥ä¹...")
        
        crawler = ZhihuCrawler()
        article = Article("æœªå‘½å", self.url)
        
        img_dir = os.path.join(self.output_dir, 'images')
        self.progress_signal.emit("ğŸ“„ æ­£åœ¨æå–æ–‡ç« å†…å®¹...")
        crawler.extract_article_content(article, self.download_images, img_dir)
        
        self.generate_files(article.title, [article], article.author)
    
    def crawl_jianshu(self):
        """çˆ¬å–ç®€ä¹¦"""
        self.progress_signal.emit("ğŸ“– æ­£åœ¨åˆ†æç®€ä¹¦...")
        
        crawler = JianshuCrawler()
        article = Article("æœªå‘½å", self.url)
        
        img_dir = os.path.join(self.output_dir, 'images')
        self.progress_signal.emit("ğŸ“„ æ­£åœ¨æå–æ–‡ç« å†…å®¹...")
        crawler.extract_article_content(article, self.download_images, img_dir)
        
        self.generate_files(article.title, [article], article.author)
    
    def generate_separate_files(self, articles: List[Article], author: str):
        """éèšåˆæ¨¡å¼ - æ¯ç¯‡æ–‡ç« å•ç‹¬ä¿å­˜"""
        self.progress_signal.emit("ğŸ“ éèšåˆæ¨¡å¼ï¼šæ¯ç¯‡æ–‡ç« å•ç‹¬ä¿å­˜...")
        
        for idx, article in enumerate(articles, 1):
            if not self.is_running:
                return
            
            # ä½¿ç”¨æ–‡ç« æ ‡é¢˜ä½œä¸ºæ–‡ä»¶å
            safe_title = re.sub(r'[\\/:"*?<>|]+', '_', article.title)
            safe_title = safe_title.strip()[:100]
            
            if not safe_title:
                safe_title = f"æ–‡ç« _{idx}"
            
            # Markdown
            if 'markdown' in self.output_formats:
                md_path = os.path.join(self.output_dir, f"{safe_title}.md")
                self.generate_markdown(md_path, article.title, [article], author)
            
            # HTML
            html_path = None
            if 'html' in self.output_formats or 'pdf' in self.output_formats:
                html_path = os.path.join(self.output_dir, f"{safe_title}.html")
                self.generate_html(html_path, article.title, [article], author)
            
            # PDF
            if 'pdf' in self.output_formats and WEASY_AVAILABLE and html_path:
                pdf_path = os.path.join(self.output_dir, f"{safe_title}.pdf")
                self.generate_pdf_professional(html_path, pdf_path)
            
            self.progress_signal.emit(f"âœ… [{idx}/{len(articles)}] {safe_title}")
    
    def generate_files(self, title: str, articles: List[Article], author: str):
        """èšåˆæ¨¡å¼ - æ‰€æœ‰æ–‡ç« åˆå¹¶æˆä¸€ä¸ªæ–‡ä»¶"""
        # ä¿®å¤æ–‡ä»¶å
        safe_title = re.sub(r'[\\/:"*?<>|]+', '_', title)
        safe_title = safe_title.strip()[:100]
        
        if not safe_title:
            safe_title = "æœªå‘½åæ–‡æ¡£"
        
        # Markdown
        if 'markdown' in self.output_formats:
            self.progress_signal.emit("ğŸ“ ç”ŸæˆMarkdown...")
            md_path = os.path.join(self.output_dir, f"{safe_title}.md")
            self.generate_markdown(md_path, title, articles, author)
        
        # HTML
        html_path = None
        if 'html' in self.output_formats or 'pdf' in self.output_formats:
            self.progress_signal.emit("ğŸŒ ç”ŸæˆHTML...")
            html_path = os.path.join(self.output_dir, f"{safe_title}.html")
            self.generate_html(html_path, title, articles, author)
        
        # PDF - ä¸“ä¸šä¹¦ç±é£æ ¼
        if 'pdf' in self.output_formats and WEASY_AVAILABLE and html_path:
            self.progress_signal.emit("ğŸ“„ ç”Ÿæˆä¸“ä¸šPDF (è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´)...")
            pdf_path = os.path.join(self.output_dir, f"{safe_title}.pdf")
            self.generate_pdf_professional(html_path, pdf_path)
    
    def generate_markdown(self, path: str, title: str, articles: List[Article], author: str):
        """ç”ŸæˆMarkdownæ–‡ä»¶"""
        with open(path, 'w', encoding='utf-8') as f:
            f.write(f"# {title}\n\n")
            f.write(f"> **ä½œè€…**: {author}\n")
            f.write(f"> **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n\n")
            f.write("---\n\n")
            
            # ç›®å½•ï¼ˆä»…åœ¨å¤šç¯‡æ–‡ç« æ—¶æ˜¾ç¤ºï¼‰
            if len(articles) > 1:
                f.write("## ğŸ“‘ ç›®å½•\n\n")
                for idx, art in enumerate(articles, 1):
                    f.write(f"{idx}. [{art.title}](#{idx})\n")
                f.write("\n---\n\n")
            
            # å†…å®¹
            for idx, art in enumerate(articles, 1):
                if len(articles) > 1:
                    f.write(f'<div id="{idx}"></div>\n\n')
                    f.write(f"## {idx}. {art.title}\n\n")
                else:
                    f.write(f"## {art.title}\n\n")
                
                if art.author:
                    f.write(f"**ä½œè€…**: {art.author}  \n")
                if art.date:
                    f.write(f"**æ—¥æœŸ**: {art.date}  \n")
                if art.category:
                    f.write(f"**åˆ†ç±»**: {art.category}  \n")
                
                f.write("\n")
                f.write(art.content)
                f.write("\n\n---\n\n")
            
            f.write("\n\n**æœ¬æ–‡æ¡£ç”±ç½‘é¡µå†…å®¹æå–å™¨ç”Ÿæˆï¼Œä»…ä¾›å­¦ä¹ ä½¿ç”¨**\n")
        
        self.progress_signal.emit(f"âœ… Markdown: {os.path.basename(path)}")
    
    def generate_html(self, path: str, title: str, articles: List[Article], author: str):
        """ç”ŸæˆHTMLæ–‡ä»¶ - GitBookä¸“ä¸šé£æ ¼ + æ•°å­¦å…¬å¼å¢å¼º"""
        html = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="{author}">
    <title>{title}</title>
    
    <!-- æ•°å­¦å…¬å¼æ”¯æŒ - MathJax 3.0 -->
    <script>
        window.MathJax = {{
            tex: {{
                inlineMath: [['$', '$'], ['\\\\(', '\\\\)']],
                displayMath: [['$$', '$$'], ['\\\\[', '\\\\]']],
                processEscapes: true,
                processEnvironments: true,
                tags: 'ams',
                autoload: {{
                    color: [],
                    colorV2: ['color']
                }},
                packages: {{'[+]': ['noerrors']}}
            }},
            options: {{
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            }},
            loader: {{
                load: ['[tex]/noerrors']
            }}
        }};
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>
    
    <style>
        /* ==================== ä¸“ä¸šä¹¦ç±é£æ ¼ - GitBookä¼˜åŒ–ç‰ˆ ==================== */
        
        /* é¡µé¢è®¾ç½® */
        @page {{
            size: A4;
            margin: 25mm 20mm;
            
            @top-center {{
                content: "{title}";
                font-size: 9pt;
                color: #999;
            }}
            
            @bottom-center {{
                content: "ç¬¬ " counter(page) " é¡µ";
                font-size: 9pt;
                color: #999;
            }}
        }}
        
        /* åŸºç¡€æ ·å¼ */
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        
        html {{
            font-size: 16px;
        }}
        
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Microsoft YaHei', 'PingFang SC', 
                         'Hiragino Sans GB', 'Noto Sans CJK SC', 'Source Han Sans CN', sans-serif;
            font-size: 1rem;
            line-height: 1.8;
            color: #2c3e50;
            background: #ffffff;
            text-rendering: optimizeLegibility;
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }}
        
        /* å®¹å™¨ */
        .book-container {{
            max-width: 900px;
            margin: 0 auto;
            padding: 40px 30px;
        }}
        
        /* å°é¢é¡µ */
        .book-cover {{
            text-align: center;
            padding: 100px 40px;
            page-break-after: always;
            border-bottom: 3px solid #3498db;
        }}
        
        .book-cover h1 {{
            font-size: 3rem;
            font-weight: 700;
            color: #2c3e50;
            margin-bottom: 30px;
            line-height: 1.3;
            letter-spacing: 2px;
        }}
        
        .book-meta {{
            font-size: 1.1rem;
            color: #7f8c8d;
            margin: 20px 0;
            line-height: 2;
        }}
        
        .book-meta strong {{
            color: #34495e;
            font-weight: 600;
        }}
        
        /* ç›®å½• */
        .toc {{
            page-break-after: always;
            padding: 40px 0;
        }}
        
        .toc-title {{
            font-size: 2.2rem;
            font-weight: 700;
            color: #2c3e50;
            margin-bottom: 40px;
            padding-bottom: 15px;
            border-bottom: 3px solid #3498db;
        }}
        
        .toc ul {{
            list-style: none;
            padding: 0;
        }}
        
        .toc li {{
            margin: 15px 0;
            padding-left: 30px;
            position: relative;
            font-size: 1.05rem;
            line-height: 1.8;
        }}
        
        .toc li::before {{
            content: "â–ª";
            position: absolute;
            left: 10px;
            color: #3498db;
            font-size: 1.2rem;
        }}
        
        .toc a {{
            color: #34495e;
            text-decoration: none;
            transition: color 0.2s;
            border-bottom: 1px solid transparent;
        }}
        
        .toc a:hover {{
            color: #3498db;
            border-bottom-color: #3498db;
        }}
        
        /* ç« èŠ‚ */
        .chapter {{
            page-break-before: always;
            padding: 30px 0;
            margin-bottom: 50px;
        }}
        
        .chapter-title {{
            font-size: 2.4rem;
            font-weight: 700;
            color: #2c3e50;
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 3px solid #3498db;
            line-height: 1.3;
        }}
        
        .chapter-meta {{
            font-size: 0.95rem;
            color: #7f8c8d;
            margin-bottom: 30px;
            padding: 12px 20px;
            background: #f8f9fa;
            border-left: 4px solid #3498db;
            border-radius: 4px;
        }}
        
        /* æ ‡é¢˜å±‚çº§ */
        .chapter h1, .chapter h2, .chapter h3, .chapter h4, .chapter h5, .chapter h6 {{
            font-weight: 600;
            line-height: 1.4;
            margin-top: 35px;
            margin-bottom: 18px;
            color: #2c3e50;
        }}
        
        .chapter h1 {{ font-size: 2.2rem; border-bottom: 2px solid #ecf0f1; padding-bottom: 12px; }}
        .chapter h2 {{ font-size: 1.9rem; }}
        .chapter h3 {{ font-size: 1.6rem; color: #34495e; }}
        .chapter h4 {{ font-size: 1.3rem; color: #34495e; }}
        .chapter h5 {{ font-size: 1.1rem; color: #34495e; }}
        .chapter h6 {{ font-size: 1rem; color: #34495e; }}
        
        /* æ®µè½ */
        .chapter p {{
            margin: 18px 0;
            font-size: 1.05rem;
            line-height: 1.9;
            text-align: justify;
            text-justify: inter-ideograph;
            color: #34495e;
        }}
        
        .chapter p:first-of-type {{
            margin-top: 0;
        }}
        
        /* ä»£ç å— */
        .code-block, pre {{
            background: #282c34;
            color: #abb2bf;
            padding: 20px 25px;
            border-radius: 6px;
            overflow-x: auto;
            margin: 25px 0;
            font-family: 'Consolas', 'Monaco', 'Courier New', 'Source Code Pro', monospace;
            font-size: 0.92rem;
            line-height: 1.6;
            border: 1px solid #21252b;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }}
        
        pre code {{
            background: transparent;
            padding: 0;
            border: none;
            color: inherit;
            font-size: inherit;
        }}
        
        /* è¡Œå†…ä»£ç  */
        code {{
            background: #f8f9fa;
            color: #e74c3c;
            padding: 3px 8px;
            border-radius: 4px;
            font-family: 'Consolas', 'Monaco', monospace;
            font-size: 0.92em;
            border: 1px solid #ecf0f1;
        }}
        
        /* æ•°å­¦å…¬å¼æ ·å¼ - å¢å¼ºç‰ˆ */
        .math-inline {{
            font-family: 'Latin Modern Math', 'STIX Two Math', 'Cambria Math', 'Times New Roman', serif;
            color: #c0392b;
            font-size: 1.05em;
            padding: 0 2px;
        }}
        
        .math-display {{
            font-family: 'Latin Modern Math', 'STIX Two Math', 'Cambria Math', 'Times New Roman', serif;
            text-align: center;
            margin: 25px 0;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 6px;
            border: 1px solid #ecf0f1;
            overflow-x: auto;
        }}
        
        /* MathJaxå…¨å±€è®¾ç½® */
        mjx-container {{
            font-size: 1.05em !important;
        }}
        
        mjx-container[display="true"] {{
            margin: 25px 0 !important;
        }}
        
        /* è¡¨æ ¼ */
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 30px 0;
            font-size: 0.98rem;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
            border-radius: 6px;
            overflow: hidden;
        }}
        
        thead {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }}
        
        th {{
            padding: 15px 18px;
            text-align: left;
            font-weight: 600;
            font-size: 1rem;
        }}
        
        td {{
            padding: 13px 18px;
            border-bottom: 1px solid #ecf0f1;
        }}
        
        tr:hover {{
            background: #f8f9fa;
        }}
        
        tr:last-child td {{
            border-bottom: none;
        }}
        
        /* å›¾ç‰‡ */
        img {{
            max-width: 100%;
            height: auto;
            display: block;
            margin: 30px auto;
            border-radius: 6px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.12);
        }}
        
        /* åˆ—è¡¨ */
        ul, ol {{
            margin: 20px 0;
            padding-left: 35px;
        }}
        
        li {{
            margin: 12px 0;
            line-height: 1.8;
            font-size: 1.02rem;
        }}
        
        ul li {{
            list-style-type: disc;
        }}
        
        ul ul li {{
            list-style-type: circle;
        }}
        
        ol li {{
            list-style-type: decimal;
        }}
        
        /* å¼•ç”¨å— */
        blockquote {{
            border-left: 4px solid #3498db;
            padding: 15px 25px;
            margin: 25px 0;
            background: #f8f9fa;
            color: #555;
            font-style: italic;
            border-radius: 0 6px 6px 0;
        }}
        
        blockquote p {{
            margin: 8px 0;
        }}
        
        /* åˆ†éš”çº¿ */
        hr {{
            border: none;
            border-top: 2px solid #ecf0f1;
            margin: 40px 0;
        }}
        
        /* é“¾æ¥ */
        a {{
            color: #3498db;
            text-decoration: none;
            border-bottom: 1px solid transparent;
            transition: all 0.2s;
        }}
        
        a:hover {{
            color: #2980b9;
            border-bottom-color: #2980b9;
        }}
        
        /* æ³¨é‡Š/æç¤ºæ¡† */
        .note, .tip, .warning {{
            padding: 18px 25px;
            margin: 25px 0;
            border-radius: 6px;
            border-left: 4px solid;
        }}
        
        .note {{
            background: #e3f2fd;
            border-color: #2196f3;
            color: #1565c0;
        }}
        
        .tip {{
            background: #e8f5e9;
            border-color: #4caf50;
            color: #2e7d32;
        }}
        
        .warning {{
            background: #fff3e0;
            border-color: #ff9800;
            color: #e65100;
        }}
        
        /* é¡µè„š */
        .book-footer {{
            text-align: center;
            padding: 50px 20px;
            margin-top: 80px;
            border-top: 2px solid #ecf0f1;
            color: #95a5a6;
            font-size: 0.95rem;
            page-break-before: always;
        }}
        
        /* æ‰“å°ä¼˜åŒ– */
        @media print {{
            body {{
                background: white;
            }}
            
            .book-container {{
                max-width: 100%;
                padding: 0;
            }}
            
            a {{
                color: #2c3e50;
                border-bottom: none;
            }}
            
            .chapter {{
                page-break-inside: avoid;
            }}
            
            h1, h2, h3, h4, h5, h6 {{
                page-break-after: avoid;
            }}
            
            img {{
                page-break-inside: avoid;
            }}
            
            pre, blockquote {{
                page-break-inside: avoid;
            }}
        }}
        
        /* å“åº”å¼ */
        @media screen and (max-width: 768px) {{
            html {{
                font-size: 14px;
            }}
            
            .book-container {{
                padding: 20px 15px;
            }}
            
            .book-cover {{
                padding: 60px 20px;
            }}
            
            .book-cover h1 {{
                font-size: 2rem;
            }}
            
            .chapter-title {{
                font-size: 1.8rem;
            }}
            
            .chapter h1 {{ font-size: 1.7rem; }}
            .chapter h2 {{ font-size: 1.5rem; }}
            .chapter h3 {{ font-size: 1.3rem; }}
        }}
    </style>
</head>
<body>
    <div class="book-container">
        <!-- å°é¢ -->
        <div class="book-cover">
            <h1>{title}</h1>
            <div class="book-meta">
                <p><strong>ä½œè€…</strong> {author}</p>
                <p><strong>ç”Ÿæˆæ—¶é—´</strong> {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}</p>
            </div>
        </div>
"""
        
        # ç›®å½•ï¼ˆä»…åœ¨å¤šç¯‡æ–‡ç« æ—¶æ˜¾ç¤ºï¼‰
        if len(articles) > 1:
            html += """
        <!-- ç›®å½• -->
        <div class="toc">
            <h2 class="toc-title">ğŸ“‘ ç›®å½•</h2>
            <ul>
"""
            for idx, art in enumerate(articles, 1):
                html += f'                <li><a href="#chapter-{idx}">{idx}. {art.title}</a></li>\n'
            
            html += """            </ul>
        </div>
"""
        
        # ç« èŠ‚å†…å®¹
        for idx, art in enumerate(articles, 1):
            meta_parts = []
            if art.author:
                meta_parts.append(f"<strong>ä½œè€…</strong> {art.author}")
            if art.date:
                meta_parts.append(f"<strong>æ—¥æœŸ</strong> {art.date}")
            if art.category:
                meta_parts.append(f"<strong>åˆ†ç±»</strong> {art.category}")
            
            meta_html = f'<div class="chapter-meta">{" | ".join(meta_parts)}</div>' if meta_parts else ''
            
            chapter_title = f"{idx}. {art.title}" if len(articles) > 1 else art.title
            
            html += f"""
        <!-- ç« èŠ‚ {idx} -->
        <div id="chapter-{idx}" class="chapter">
            <h1 class="chapter-title">{chapter_title}</h1>
            {meta_html}
            <div class="chapter-content">
                {art.html_content}
            </div>
        </div>
"""
        
        # é¡µè„š
        html += f"""
        <!-- é¡µè„š -->
        <div class="book-footer">
            <p>æœ¬æ–‡æ¡£ç”±ç½‘é¡µå†…å®¹æå–å™¨ v7.0 ç”Ÿæˆ</p>
            <p>ä»…ä¾›ä¸ªäººå­¦ä¹ ä½¿ç”¨ï¼Œè¯·å‹¿ç”¨äºå•†ä¸šç”¨é€”</p>
            <p>ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
    </div>
</body>
</html>
"""
        
        with open(path, 'w', encoding='utf-8') as f:
            f.write(html)
        
        self.progress_signal.emit(f"âœ… HTML: {os.path.basename(path)}")
    
    def generate_pdf_professional(self, html_path: str, pdf_path: str):
        """ç”Ÿæˆä¸“ä¸šä¹¦ç±é£æ ¼çš„PDF - WeasyPrint 59.0+"""
        try:
            # è¯»å–HTMLå†…å®¹
            with open(html_path, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            # åˆ›å»ºå­—ä½“é…ç½®
            font_config = FontConfiguration()
            
            # PDFä¸“ç”¨CSS - å¢å¼ºæ‰“å°æ•ˆæœ
            pdf_css = """
                @page {
                    size: A4;
                    margin: 25mm 20mm;
                }
                
                body {
                    font-family: 'Microsoft YaHei', 'SimSun', 'SimHei', 'PingFang SC', sans-serif;
                    font-size: 11pt;
                    line-height: 1.7;
                }
                
                .chapter {
                    page-break-before: always;
                }
                
                .toc {
                    page-break-after: always;
                }
                
                h1, h2, h3, h4 {
                    page-break-after: avoid;
                }
                
                pre, blockquote, table, img {
                    page-break-inside: avoid;
                }
                
                .math-inline, .math-display {
                    font-family: 'Times New Roman', 'STIX Two Math', serif;
                }
                
                code {
                    background: #f4f4f4;
                    border: 1px solid #ddd;
                    padding: 2px 6px;
                    border-radius: 3px;
                }
                
                pre {
                    background: #2d2d2d;
                    color: #f8f8f2;
                    padding: 15px;
                    border-radius: 5px;
                    font-size: 9pt;
                }
            """
            
            # ç”ŸæˆPDF
            html_doc = HTML(string=html_content, base_url=os.path.dirname(html_path))
            css_doc = CSS(string=pdf_css, font_config=font_config)
            
            html_doc.write_pdf(
                target=pdf_path,
                stylesheets=[css_doc],
                font_config=font_config
            )
            
            self.progress_signal.emit(f"âœ… PDF: {os.path.basename(pdf_path)}")
            
        except Exception as e:
            import traceback
            error_msg = f"âš ï¸ PDFç”Ÿæˆå¤±è´¥: {str(e)}\n{traceback.format_exc()}"
            self.progress_signal.emit(error_msg)
            print(error_msg)


# ======================== ä¸»çª—å£ - GUIå¢å¼ºç‰ˆ ========================
class MainWindow(QMainWindow):
    """ä¸»çª—å£ - å¤§å­—ä½“ã€æ˜“æ“ä½œ"""
    
    def __init__(self):
        super().__init__()
        self.spider = None
        self.settings = QSettings('WebContentExtractor', 'v7')
        self.init_ui()
        self.load_settings()
        
    def init_ui(self):
        self.setWindowTitle('ğŸŒ ç½‘é¡µå†…å®¹æå–å™¨ v7.0 - ä¸“ä¸šå¢å¼ºç‰ˆ')
        self.setGeometry(100, 100, 1200, 900)
        self.setMinimumSize(1000, 800)
        
        # ä¼˜åŒ–æ ·å¼ - å¤§å­—ä½“ã€ä¸“ä¸šå¤–è§‚
        self.setStyleSheet("""
            QMainWindow {
                background: #f5f7fa;
            }
            QWidget {
                font-size: 16px;
            }
            QGroupBox {
                border: 2px solid #dfe6e9;
                border-radius: 10px;
                margin-top: 20px;
                padding: 25px 18px 18px 18px;
                font-weight: 600;
                font-size: 17px;
                background: white;
            }
            QGroupBox::title {
                subcontrol-origin: margin;
                left: 20px;
                padding: 0 10px;
                background: white;
                font-size: 18px;
                color: #2c3e50;
            }
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #667eea, stop:1 #764ba2);
                color: white;
                border: none;
                padding: 16px 28px;
                border-radius: 8px;
                font-size: 16px;
                font-weight: 600;
                min-width: 130px;
            }
            QPushButton:hover {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #5568d3, stop:1 #6a3f8f);
            }
            QPushButton:pressed {
                background: #5568d3;
            }
            QPushButton:disabled {
                background: #bdc3c7;
            }
            QLineEdit {
                padding: 14px;
                border: 2px solid #dfe6e9;
                border-radius: 8px;
                background: white;
                font-size: 16px;
            }
            QLineEdit:focus {
                border: 2px solid #667eea;
            }
            QTextEdit {
                border: 2px solid #dfe6e9;
                border-radius: 8px;
                background: white;
                padding: 14px;
                font-family: 'Consolas', 'Monaco', monospace;
                font-size: 15px;
                line-height: 1.6;
            }
            QRadioButton, QCheckBox {
                spacing: 10px;
                font-size: 16px;
            }
            QRadioButton::indicator, QCheckBox::indicator {
                width: 20px;
                height: 20px;
            }
            QProgressBar {
                border: 2px solid #dfe6e9;
                border-radius: 8px;
                text-align: center;
                background: white;
                height: 35px;
                font-size: 15px;
            }
            QProgressBar::chunk {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:0,
                    stop:0 #667eea, stop:1 #764ba2);
                border-radius: 6px;
            }
            QLabel {
                color: #2c3e50;
                font-size: 16px;
            }
        """)
        
        central = QWidget()
        self.setCentralWidget(central)
        layout = QVBoxLayout(central)
        layout.setSpacing(16)
        layout.setContentsMargins(16, 16, 16, 16)
        
        # æ ‡é¢˜
        title_widget = QWidget()
        title_widget.setStyleSheet("""
            background: qlineargradient(x1:0, y1:0, x2:1, y2:0,
                stop:0 #667eea, stop:1 #764ba2);
            border-radius: 12px;
        """)
        title_layout = QVBoxLayout(title_widget)
        title_layout.setContentsMargins(25, 25, 25, 25)
        
        title_label = QLabel("ğŸŒ ç½‘é¡µå†…å®¹æå–å™¨ v7.0")
        title_label.setFont(QFont('Microsoft YaHei', 24, QFont.Bold))
        title_label.setStyleSheet("color: white;")
        title_label.setAlignment(Qt.AlignCenter)
        
        subtitle = QLabel("ä¸“ä¸šç‰ˆ | PDFä¹¦ç±é£æ ¼ | æ•°å­¦å…¬å¼å¢å¼º | CSDNæ·±åº¦æå– | å¤§å­—ä½“GUI")
        subtitle.setStyleSheet("color: rgba(255,255,255,0.95); font-size: 15px;")
        subtitle.setAlignment(Qt.AlignCenter)
        
        title_layout.addWidget(title_label)
        title_layout.addWidget(subtitle)
        layout.addWidget(title_widget)
        
        # URLè¾“å…¥
        url_group = QGroupBox("ğŸ”— è¾“å…¥ç½‘å€")
        url_layout = QVBoxLayout()
        url_layout.setSpacing(14)
        
        # å¹³å°é€‰æ‹©
        platform_layout = QHBoxLayout()
        platform_layout.setSpacing(16)
        platform_layout.addWidget(QLabel("å¹³å°:"))
        
        self.runoob_radio = QRadioButton("ğŸ“˜ èœé¸Ÿæ•™ç¨‹")
        self.csdn_radio = QRadioButton("ğŸ“™ CSDNåšå®¢")
        self.zhihu_radio = QRadioButton("ğŸ“— çŸ¥ä¹ä¸“æ ")
        self.jianshu_radio = QRadioButton("ğŸ“• ç®€ä¹¦")
        self.runoob_radio.setChecked(True)
        
        platform_layout.addWidget(self.runoob_radio)
        platform_layout.addWidget(self.csdn_radio)
        platform_layout.addWidget(self.zhihu_radio)
        platform_layout.addWidget(self.jianshu_radio)
        platform_layout.addStretch()
        url_layout.addLayout(platform_layout)
        
        # URLè¾“å…¥
        url_input_layout = QHBoxLayout()
        url_input_layout.setSpacing(10)
        url_label = QLabel("ç½‘å€:")
        url_label.setMinimumWidth(50)
        url_input_layout.addWidget(url_label)
        self.url_input = QLineEdit()
        self.url_input.setPlaceholderText("ç²˜è´´å®Œæ•´URL (æ”¯æŒæ•™ç¨‹é¦–é¡µã€å•ç¯‡æ–‡ç« ã€ä¸“æ )...")
        url_input_layout.addWidget(self.url_input, 1)
        url_layout.addLayout(url_input_layout)
        
        # ç¤ºä¾‹
        example = QLabel(
            "ğŸ’¡ æ”¯æŒçš„URLæ ¼å¼:\n"
            "â€¢ èœé¸Ÿæ•™ç¨‹: https://www.runoob.com/python3/python3-tutorial.html\n"
            "â€¢ CSDNæ–‡ç« : https://blog.csdn.net/xxx/article/details/123456\n"
            "â€¢ çŸ¥ä¹ä¸“æ : https://zhuanlan.zhihu.com/p/123456789\n"
            "â€¢ ç®€ä¹¦æ–‡ç« : https://www.jianshu.com/p/123456789abc"
        )
        example.setStyleSheet("color: #7f8c8d; font-size: 14px; padding: 12px; background: #f8f9fa; border-radius: 6px;")
        url_layout.addWidget(example)
        
        url_group.setLayout(url_layout)
        layout.addWidget(url_group)
        
        # è¾“å‡ºè®¾ç½®
        output_group = QGroupBox("âš™ï¸ è¾“å‡ºè®¾ç½®")
        output_layout = QVBoxLayout()
        output_layout.setSpacing(14)
        
        # è¾“å‡ºç›®å½•
        dir_layout = QHBoxLayout()
        dir_layout.setSpacing(10)
        dir_label = QLabel("ç›®å½•:")
        dir_label.setMinimumWidth(50)
        dir_layout.addWidget(dir_label)
        self.output_path = QLineEdit('./output')
        dir_layout.addWidget(self.output_path, 1)
        browse_btn = QPushButton("ğŸ“ æµè§ˆ")
        browse_btn.setMaximumWidth(120)
        browse_btn.clicked.connect(self.browse_output_dir)
        dir_layout.addWidget(browse_btn)
        output_layout.addLayout(dir_layout)
        
        # æ ¼å¼é€‰æ‹©
        format_layout = QHBoxLayout()
        format_layout.setSpacing(16)
        format_label = QLabel("æ ¼å¼:")
        format_label.setMinimumWidth(50)
        format_layout.addWidget(format_label)
        
        self.md_check = QCheckBox("ğŸ“ Markdown")
        self.html_check = QCheckBox("ğŸŒ HTML")
        self.pdf_check = QCheckBox("ğŸ“„ PDF (ä¸“ä¸šä¹¦ç±)")
        
        self.md_check.setChecked(True)
        self.html_check.setChecked(True)
        if WEASY_AVAILABLE:
            self.pdf_check.setChecked(True)
        else:
            self.pdf_check.setEnabled(False)
            self.pdf_check.setToolTip("éœ€è¦å®‰è£… weasyprint")
        
        format_layout.addWidget(self.md_check)
        format_layout.addWidget(self.html_check)
        format_layout.addWidget(self.pdf_check)
        
        self.download_img_check = QCheckBox("ğŸ–¼ï¸ ä¸‹è½½å›¾ç‰‡")
        self.download_img_check.setChecked(True)
        format_layout.addWidget(self.download_img_check)
        
        # éèšåˆæ¨¡å¼
        self.separate_mode_check = QCheckBox("ğŸ“‘ éèšåˆæ¨¡å¼ï¼ˆæ¯ç¯‡ç‹¬ç«‹ï¼‰")
        self.separate_mode_check.setChecked(False)
        self.separate_mode_check.setToolTip("å‹¾é€‰åï¼Œå¤šç¯‡æ–‡ç« å°†åˆ†åˆ«ä¿å­˜ä¸ºç‹¬ç«‹æ–‡ä»¶")
        format_layout.addWidget(self.separate_mode_check)
        
        format_layout.addStretch()
        output_layout.addLayout(format_layout)
        
        if not WEASY_AVAILABLE:
            pdf_hint = QLabel("ğŸ’¡ å®‰è£… weasyprint ä»¥å¯ç”¨PDFåŠŸèƒ½\n   å‘½ä»¤: pip install weasyprint")
            pdf_hint.setStyleSheet("color: #f39c12; font-size: 14px; padding: 10px;")
            output_layout.addWidget(pdf_hint)
        
        output_group.setLayout(output_layout)
        layout.addWidget(output_group)
        
        # æ§åˆ¶æŒ‰é’®
        control_layout = QHBoxLayout()
        control_layout.setSpacing(16)
        
        self.start_btn = QPushButton("ğŸš€ å¼€å§‹æå–")
        self.start_btn.clicked.connect(self.start_crawling)
        self.start_btn.setMinimumHeight(55)
        
        self.stop_btn = QPushButton("â¹ï¸ åœæ­¢")
        self.stop_btn.clicked.connect(self.stop_crawling)
        self.stop_btn.setEnabled(False)
        self.stop_btn.setMinimumHeight(55)
        
        open_btn = QPushButton("ğŸ“‚ æ‰“å¼€æ–‡ä»¶å¤¹")
        open_btn.clicked.connect(self.open_output_folder)
        open_btn.setMinimumHeight(55)
        
        control_layout.addWidget(self.start_btn, 2)
        control_layout.addWidget(self.stop_btn, 1)
        control_layout.addWidget(open_btn, 1)
        layout.addLayout(control_layout)
        
        # è¿›åº¦æ¡
        self.progress_bar = QProgressBar()
        self.progress_bar.setTextVisible(False)
        self.progress_bar.setRange(0, 0)
        layout.addWidget(self.progress_bar)
        
        # æ—¥å¿—
        log_label = QLabel("ğŸ“‹ è¿è¡Œæ—¥å¿—")
        log_label.setFont(QFont('Microsoft YaHei', 14, QFont.Bold))
        layout.addWidget(log_label)
        
        self.log_text = QTextEdit()
        self.log_text.setReadOnly(True)
        self.log_text.setMinimumHeight(220)
        layout.addWidget(self.log_text)
        
    def browse_output_dir(self):
        directory = QFileDialog.getExistingDirectory(self, "é€‰æ‹©è¾“å‡ºç›®å½•")
        if directory:
            self.output_path.setText(directory)
            
    def open_output_folder(self):
        path = os.path.abspath(self.output_path.text())
        if os.path.exists(path):
            if sys.platform == 'win32':
                os.startfile(path)
            elif sys.platform == 'darwin':
                os.system(f'open "{path}"')
            else:
                os.system(f'xdg-open "{path}"')
        else:
            QMessageBox.warning(self, "æç¤º", "è¾“å‡ºç›®å½•ä¸å­˜åœ¨")
            
    def start_crawling(self):
        url = self.url_input.text().strip()
        if not url:
            QMessageBox.warning(self, "æç¤º", "è¯·è¾“å…¥URL!")
            return
        
        if not url.startswith('http'):
            QMessageBox.warning(self, "æç¤º", "è¯·è¾“å…¥å®Œæ•´çš„URL (ä»¥httpå¼€å¤´)")
            return
        
        # æ£€æŸ¥æ ¼å¼
        formats = []
        if self.md_check.isChecked():
            formats.append('markdown')
        if self.html_check.isChecked():
            formats.append('html')
        if self.pdf_check.isChecked():
            formats.append('pdf')
        
        if not formats:
            QMessageBox.warning(self, "æç¤º", "è¯·è‡³å°‘é€‰æ‹©ä¸€ç§è¾“å‡ºæ ¼å¼!")
            return
        
        # åˆ¤æ–­å¹³å°
        if self.runoob_radio.isChecked():
            platform = 'runoob'
        elif self.csdn_radio.isChecked():
            platform = 'csdn'
        elif self.zhihu_radio.isChecked():
            platform = 'zhihu'
        else:
            platform = 'jianshu'
        
        # åˆ›å»ºçˆ¬è™«çº¿ç¨‹
        self.spider = CrawlerThread()
        self.spider.url = url
        self.spider.platform = platform
        self.spider.output_dir = self.output_path.text()
        self.spider.output_formats = formats
        self.spider.download_images = self.download_img_check.isChecked()
        self.spider.aggregate_mode = not self.separate_mode_check.isChecked()
        
        self.spider.progress_signal.connect(self.update_progress)
        self.spider.finished_signal.connect(self.crawl_finished)
        
        self.start_btn.setEnabled(False)
        self.stop_btn.setEnabled(True)
        self.progress_bar.setRange(0, 0)
        self.log_text.clear()
        
        self.spider.start()
        mode_text = "èšåˆæ¨¡å¼ï¼ˆåˆå¹¶æˆä¸€ä¸ªæ–‡ä»¶ï¼‰" if self.spider.aggregate_mode else "éèšåˆæ¨¡å¼ï¼ˆæ¯ç¯‡ç‹¬ç«‹æ–‡ä»¶ï¼‰"
        self.log("=" * 80)
        self.log(f"ğŸš€ å¼€å§‹æå–")
        self.log(f"ğŸ“ URL: {url}")
        self.log(f"ğŸ“¦ å¹³å°: {platform}")
        self.log(f"ğŸ“ æ ¼å¼: {', '.join(formats)}")
        self.log(f"ğŸ“„ æ¨¡å¼: {mode_text}")
        self.log("=" * 80)
        
    def stop_crawling(self):
        if self.spider:
            self.spider.stop()
            self.log("â¹ï¸ æ­£åœ¨åœæ­¢...")
            
    def update_progress(self, message: str):
        self.log(message)
        
    def crawl_finished(self, success: bool, message: str):
        self.log("=" * 80)
        self.log(message)
        self.log("=" * 80)
        self.start_btn.setEnabled(True)
        self.stop_btn.setEnabled(False)
        self.progress_bar.setRange(0, 100)
        self.progress_bar.setValue(100 if success else 0)
        
        if success:
            QMessageBox.information(self, "âœ… å®Œæˆ", message)
        else:
            QMessageBox.critical(self, "âŒ é”™è¯¯", message)
            
    def log(self, message: str):
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.log_text.append(f"[{timestamp}] {message}")
        self.log_text.moveCursor(QTextCursor.End)
        
    def load_settings(self):
        output = self.settings.value('output_dir', './output')
        self.output_path.setText(output)
        
    def closeEvent(self, event):
        self.settings.setValue('output_dir', self.output_path.text())
        if self.spider and self.spider.isRunning():
            reply = QMessageBox.question(
                self, 
                'ç¡®è®¤', 
                'ä»»åŠ¡æ­£åœ¨è¿›è¡Œï¼Œç¡®å®šé€€å‡ºå—?',
                QMessageBox.Yes | QMessageBox.No
            )
            if reply == QMessageBox.Yes:
                self.spider.stop()
                self.spider.wait()
                event.accept()
            else:
                event.ignore()
        else:
            event.accept()


# ======================== ä¸»ç¨‹åºå…¥å£ ========================
def main():
    app = QApplication(sys.argv)
    app.setStyle('Fusion')
    
    # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
    splash = QMessageBox()
    splash.setWindowTitle("ç½‘é¡µå†…å®¹æå–å™¨ v7.0")
    splash.setIcon(QMessageBox.Information)
    
    status_text = "âœ… åŠŸèƒ½çŠ¶æ€:\n\n"
    status_text += "â€¢ Markdownè¾“å‡º: âœ… å¯ç”¨\n"
    status_text += "â€¢ HTMLè¾“å‡º: âœ… GitBooké£æ ¼\n"
    status_text += "â€¢ æ•°å­¦å…¬å¼: âœ… MathJax 3.0 å®Œæ•´æ”¯æŒ\n"
    status_text += "â€¢ å›¾ç‰‡ä¸‹è½½: âœ… å¯ç”¨\n"
    status_text += "â€¢ éèšåˆæ¨¡å¼: âœ… æ”¯æŒç‹¬ç«‹æ–‡ä»¶\n"
    status_text += "â€¢ CSDNå¢å¼º: âœ… æ·±åº¦å†…å®¹æå–\n"
    status_text += "â€¢ GUIä¼˜åŒ–: âœ… å¤§å­—ä½“æ˜“æ“ä½œ\n"
    
    if WEASY_AVAILABLE:
        status_text += "â€¢ PDFè¾“å‡º: âœ… ä¸“ä¸šä¹¦ç±é£æ ¼\n"
    else:
        status_text += "â€¢ PDFè¾“å‡º: âŒ æœªå®‰è£…\n"
        status_text += "\nğŸ’¡ å®‰è£…PDFæ”¯æŒ:\n"
        status_text += "pip install weasyprint\n"
    
    status_text += "\nğŸŒ æ”¯æŒå¹³å°:\n"
    status_text += "â€¢ èœé¸Ÿæ•™ç¨‹ã€CSDNã€çŸ¥ä¹ã€ç®€ä¹¦"
    
    splash.setText(status_text)
    splash.setStandardButtons(QMessageBox.Ok)
    splash.exec_()
    
    window = MainWindow()
    window.show()
    
    sys.exit(app.exec_())


if __name__ == '__main__':
    main()